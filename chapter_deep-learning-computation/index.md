# Deep Learning Computation
:label:`chapter_computation`

In the previous chapters, we introduced the concepts of machine learning,
and ramped up to modern deep learning techniques, 
implementing each component of a multilayer perceptron from scratch
and showing how to take advantage of MXNet's Gluon library 
to roll out the same models effortlessly.
To get you that far that fast, although we *called upon* the libraries,
but skipped over more advanced details about *how they work*.

In this chapter, we will go deeper into the key components 
of deep learning computation, focusing on model construction, 
parameter access and initialization, designing custom layers, 
reading and writing models for persistence, and leveraging GPUs. 
These insights will move you from *end user* to *power user*,
giving you the tools needed to combine the reap the benefits 
of a mature deep learning library, while retaining the flexibility
to implement more complex models, including those you invent yourself!
While this chapter does not introduce any new models or datasets,
the advanced modeling chapters that follow rely heavily on these techniques.

```toc
:maxdepth: 2

model-construction
parameters
deferred-init
custom-layer
read-write
use-gpu
```
